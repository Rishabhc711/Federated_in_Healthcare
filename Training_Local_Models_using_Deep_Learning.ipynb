{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Local Models using Deep Learning",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fchyYKS8lt915GKrdsrXRfNru9ZByxpT",
      "authorship_tag": "ABX9TyMok93y88cZ/l2x7KS88i71",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishabhc711/Federated_in_Healthcare/blob/main/Training_Local_Models_using_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fzwqhcpMGaJ9",
        "outputId": "fd598d5b-20b4-4198-b40c-5aa583bd7bf8"
      },
      "source": [
        "# Artificial Neural Network\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2f1jglzJCyS"
      },
      "source": [
        "# Part 1 - Data Preprocessing\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Datasets/Diabetes Dataset/diabetes1.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSGoQky-JGgZ"
      },
      "source": [
        "# # Encoding categorical data\n",
        "# # Label Encoding the \"Gender\" column\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# le = LabelEncoder()\n",
        "# X[:, 2] = le.fit_transform(X[:, 2])\n",
        "# print(X)\n",
        "# # One Hot Encoding the \"Geography\" column\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "# X = np.array(ct.fit_transform(X))\n",
        "# print(X)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTFgl6gmJKRz",
        "outputId": "2f4a25cb-49fc-49d8-c78f-7f6b08e39237"
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "print(X)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.5153943   0.52455322 -0.37248123 ...  0.17268332 -1.06324616\n",
            "   1.18042417]\n",
            " [-1.12049474 -1.1597562   0.67008046 ...  0.73724853 -0.7355513\n",
            "  -0.85632626]\n",
            " [-1.12049474  0.74288962 -3.60442246 ...  1.47363794  0.49175869\n",
            "  -0.17740945]\n",
            " ...\n",
            " [ 0.69480658 -1.12856529  0.46156812 ... -0.12187245 -0.27492362\n",
            "   0.75610116]\n",
            " [-1.12049474  0.24383498  2.12966682 ...  4.28419085 -0.46968566\n",
            "  -0.60173245]\n",
            " [-0.5153943  -1.25332895  0.14879962 ... -0.25687717  0.23516743\n",
            "  -0.68659705]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTGGr4YNJLyi"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rilgm660JNmr",
        "outputId": "2fb67ae8-2a4d-4abc-f1ce-f6843adff428"
      },
      "source": [
        " # Building the ANN\n",
        "\n",
        "# Initializing the ANN\n",
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Training the ANN\n",
        "\n",
        "# Compiling the ANN\n",
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Training the ANN on the Training set\n",
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)\n",
        "\n",
        "ann.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 1s 1ms/step - loss: 0.6201 - accuracy: 0.6970\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.7162\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7582\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7819\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7805\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7697\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7772\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7879\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7847\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8119\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7849\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8013\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7980\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.8031\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7900\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7811\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7979\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8132\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8128\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8091\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8081\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8145\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8004\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8130\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8043\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8212\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8202\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8080\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8057\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8066\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8094\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4035 - accuracy: 0.8157\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3811 - accuracy: 0.8326\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3659 - accuracy: 0.8432\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8398\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8534\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8164\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3689 - accuracy: 0.8411\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8402\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8347\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8364\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8450\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8413\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8414\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8698\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8634\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8577\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8389\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8595\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.8559\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8481\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8678\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3209 - accuracy: 0.8628\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8765\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8594\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8781\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8701\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8717\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8734\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8781\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8608\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8795\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.8854\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8756\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.8813\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.8787\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.8829\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2901 - accuracy: 0.8750\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8890\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.8854\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8927\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.8864\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8797\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8758\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8773\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8692\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.8748\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2672 - accuracy: 0.8931\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.8956\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.8846\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2715 - accuracy: 0.8915\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.8794\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2689 - accuracy: 0.8928\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8782\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2797 - accuracy: 0.8836\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2559 - accuracy: 0.8971\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.9025\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2774 - accuracy: 0.8920\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2720 - accuracy: 0.8908\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2603 - accuracy: 0.9006\n",
            "Epoch 91/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.9068\n",
            "Epoch 92/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.8980\n",
            "Epoch 93/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.9009\n",
            "Epoch 94/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9134\n",
            "Epoch 95/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.8973\n",
            "Epoch 96/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.9035\n",
            "Epoch 97/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.8904\n",
            "Epoch 98/100\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9065\n",
            "Epoch 99/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9059\n",
            "Epoch 100/100\n",
            "50/50 [==============================] - 0s 1ms/step - loss: 0.2596 - accuracy: 0.8997\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (32, 16)                  144       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (32, 16)                  272       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (32, 8)                   136       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (32, 1)                   9         \n",
            "=================================================================\n",
            "Total params: 561\n",
            "Trainable params: 561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjEBal-GMdoT"
      },
      "source": [
        "w1, b1 = ann.layers[0].get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpJ27DUGMiaC"
      },
      "source": [
        "layers=ann.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iew39EqMmAa",
        "outputId": "29902ac0-c310-4741-ade2-8b30041b0706"
      },
      "source": [
        "layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Dense at 0x7fe61e751310>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fe61e29bed0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fe61e2add50>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7fe61e2add90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2gVW__CMmmj",
        "outputId": "f664b4f7-cf86-4a1a-a88d-2a4d9e5cff7b"
      },
      "source": [
        "w1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.18961778,  0.36971042, -0.6922349 ,  0.26433265, -0.29133192,\n",
              "        -0.35076794, -0.20166479,  0.37977955, -0.15369253, -0.49147448,\n",
              "         0.8395925 ,  0.2562585 ,  0.00734618, -0.1672067 , -0.00117301,\n",
              "        -0.37151274],\n",
              "       [-0.15063033, -0.7940601 ,  0.57124925, -0.6806014 ,  0.04762609,\n",
              "         0.76367474, -0.41792044,  0.31792733,  0.5403062 , -0.19733834,\n",
              "        -0.02220407, -0.38489965, -0.5873822 , -0.40895733,  0.44811124,\n",
              "        -0.31531945],\n",
              "       [ 0.17876628, -0.4153071 , -0.5575278 ,  0.9612843 , -0.07667277,\n",
              "        -0.37272432,  0.48295856, -0.328215  , -0.03510686, -0.18232842,\n",
              "        -0.22206484,  0.17243765, -0.19259767, -0.09992103,  0.47071832,\n",
              "        -0.69496757],\n",
              "       [-0.01969525, -0.21636781,  0.6458948 , -0.11231512, -0.4641609 ,\n",
              "        -0.35238248, -0.3922688 ,  0.12780902, -0.8313623 , -0.3912221 ,\n",
              "        -0.04506451,  0.26079023, -0.21366473,  0.3279267 , -0.37674475,\n",
              "        -0.74887425],\n",
              "       [-0.21958987, -0.09353731,  0.18627632,  0.0650219 , -0.7308887 ,\n",
              "         0.15824112,  0.14688642,  0.37573645,  0.13141559,  0.33122358,\n",
              "        -0.07552894, -0.5193543 ,  0.45282596,  0.27830374,  0.65348786,\n",
              "        -0.25169995],\n",
              "       [-0.5385451 ,  0.27903837, -0.14094631, -0.32022297,  0.7099457 ,\n",
              "        -0.58536214,  0.50180185, -0.08968103, -0.08600586,  0.41768256,\n",
              "        -0.15587404,  0.42986906, -0.15870424, -0.08170402,  0.26557916,\n",
              "        -0.53699625],\n",
              "       [-0.42068395, -0.6248126 , -0.44705853, -0.08670957,  0.25944215,\n",
              "         0.4353616 , -0.3473534 ,  0.00801016,  0.35694164,  0.32924265,\n",
              "        -0.01003848, -0.8582007 ,  0.6970031 ,  0.09873217,  0.6637789 ,\n",
              "        -0.21239915],\n",
              "       [-0.61841506, -0.1027655 , -0.50968915,  0.5159627 , -0.05993361,\n",
              "         0.2384306 , -0.6907631 ,  0.34041187,  0.48378408,  0.7167109 ,\n",
              "        -0.5586886 ,  0.47210535,  0.05037719, -0.5464535 ,  0.36003467,\n",
              "         0.1153517 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8hNmV27Mtjw",
        "outputId": "07248406-e8c7-4be5-9b17-2ceaf138f8fa"
      },
      "source": [
        "b1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.307377  ,  0.13057391,  0.36060163, -0.00093751,  0.06067311,\n",
              "        0.21035309,  0.00944315,  0.20950375, -0.08014739, -0.21312034,\n",
              "        0.03905988, -0.27543092,  0.14827408,  0.0711429 ,  0.1528475 ,\n",
              "        0.14207214], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU2MsCPiMuSv",
        "outputId": "e508d4b8-1489-458a-e7b8-7d94e7cc7a60"
      },
      "source": [
        "weights=[]\n",
        "for layer in ann.layers:\n",
        "    weights.append(layer.get_weights())\n",
        "    print(layer)\n",
        "print(weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fe61e751310>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fe61e29bed0>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fe61e2add50>\n",
            "<tensorflow.python.keras.layers.core.Dense object at 0x7fe61e2add90>\n",
            "[[array([[ 0.18961778,  0.36971042, -0.6922349 ,  0.26433265, -0.29133192,\n",
            "        -0.35076794, -0.20166479,  0.37977955, -0.15369253, -0.49147448,\n",
            "         0.8395925 ,  0.2562585 ,  0.00734618, -0.1672067 , -0.00117301,\n",
            "        -0.37151274],\n",
            "       [-0.15063033, -0.7940601 ,  0.57124925, -0.6806014 ,  0.04762609,\n",
            "         0.76367474, -0.41792044,  0.31792733,  0.5403062 , -0.19733834,\n",
            "        -0.02220407, -0.38489965, -0.5873822 , -0.40895733,  0.44811124,\n",
            "        -0.31531945],\n",
            "       [ 0.17876628, -0.4153071 , -0.5575278 ,  0.9612843 , -0.07667277,\n",
            "        -0.37272432,  0.48295856, -0.328215  , -0.03510686, -0.18232842,\n",
            "        -0.22206484,  0.17243765, -0.19259767, -0.09992103,  0.47071832,\n",
            "        -0.69496757],\n",
            "       [-0.01969525, -0.21636781,  0.6458948 , -0.11231512, -0.4641609 ,\n",
            "        -0.35238248, -0.3922688 ,  0.12780902, -0.8313623 , -0.3912221 ,\n",
            "        -0.04506451,  0.26079023, -0.21366473,  0.3279267 , -0.37674475,\n",
            "        -0.74887425],\n",
            "       [-0.21958987, -0.09353731,  0.18627632,  0.0650219 , -0.7308887 ,\n",
            "         0.15824112,  0.14688642,  0.37573645,  0.13141559,  0.33122358,\n",
            "        -0.07552894, -0.5193543 ,  0.45282596,  0.27830374,  0.65348786,\n",
            "        -0.25169995],\n",
            "       [-0.5385451 ,  0.27903837, -0.14094631, -0.32022297,  0.7099457 ,\n",
            "        -0.58536214,  0.50180185, -0.08968103, -0.08600586,  0.41768256,\n",
            "        -0.15587404,  0.42986906, -0.15870424, -0.08170402,  0.26557916,\n",
            "        -0.53699625],\n",
            "       [-0.42068395, -0.6248126 , -0.44705853, -0.08670957,  0.25944215,\n",
            "         0.4353616 , -0.3473534 ,  0.00801016,  0.35694164,  0.32924265,\n",
            "        -0.01003848, -0.8582007 ,  0.6970031 ,  0.09873217,  0.6637789 ,\n",
            "        -0.21239915],\n",
            "       [-0.61841506, -0.1027655 , -0.50968915,  0.5159627 , -0.05993361,\n",
            "         0.2384306 , -0.6907631 ,  0.34041187,  0.48378408,  0.7167109 ,\n",
            "        -0.5586886 ,  0.47210535,  0.05037719, -0.5464535 ,  0.36003467,\n",
            "         0.1153517 ]], dtype=float32), array([ 0.307377  ,  0.13057391,  0.36060163, -0.00093751,  0.06067311,\n",
            "        0.21035309,  0.00944315,  0.20950375, -0.08014739, -0.21312034,\n",
            "        0.03905988, -0.27543092,  0.14827408,  0.0711429 ,  0.1528475 ,\n",
            "        0.14207214], dtype=float32)], [array([[-2.16931626e-02, -4.20106024e-01,  2.25660399e-01,\n",
            "         2.80335426e-01, -1.60401147e-02, -2.01006621e-01,\n",
            "        -8.42118919e-01,  3.84156227e-01, -1.81778207e-01,\n",
            "         4.59364355e-01,  4.71248537e-01,  8.46306533e-02,\n",
            "         5.26839256e-01,  2.64463186e-01, -2.68427908e-01,\n",
            "         5.50474823e-01],\n",
            "       [-5.64383447e-01,  1.45220533e-01,  1.35518080e-02,\n",
            "         3.22282553e-01,  4.24889803e-01,  2.06886023e-01,\n",
            "        -1.54617071e-01,  1.78268313e-01,  2.92924047e-01,\n",
            "         4.52222705e-01, -1.92352369e-01,  4.79798615e-01,\n",
            "         1.10460721e-01, -1.36770293e-01,  3.69637907e-01,\n",
            "        -7.49771530e-03],\n",
            "       [ 5.98809779e-01,  2.89476335e-01, -1.11082785e-01,\n",
            "         1.90258548e-01, -2.12670550e-01, -1.10770039e-01,\n",
            "         3.63387734e-01, -1.10315716e+00, -1.92264572e-01,\n",
            "        -3.28757882e-01, -4.31971282e-01, -2.80473292e-01,\n",
            "         1.64181113e-01, -2.16007963e-01, -1.17073730e-02,\n",
            "         5.43893814e-01],\n",
            "       [ 4.95016158e-01, -1.84586734e-01, -3.21097255e-01,\n",
            "         3.74851614e-01,  4.58880439e-02, -4.59596932e-01,\n",
            "         6.65615320e-01, -1.95508078e-01, -8.59794468e-02,\n",
            "        -8.96329284e-02,  4.35407996e-01, -5.71816489e-02,\n",
            "        -3.34758699e-01,  1.74060017e-01,  2.46537536e-01,\n",
            "         3.51436466e-01],\n",
            "       [ 2.75789499e-01,  4.11310136e-01,  3.98337454e-01,\n",
            "         6.73047528e-02, -5.06959200e-01, -3.03330511e-01,\n",
            "        -1.43075898e-01,  4.05748278e-01,  3.80037367e-01,\n",
            "         3.48116875e-01, -9.02131721e-02,  4.83178735e-01,\n",
            "         1.13435034e-02, -4.82451528e-01, -3.78352314e-01,\n",
            "        -9.58982334e-02],\n",
            "       [-2.10384816e-01,  5.92114590e-02,  1.25985816e-02,\n",
            "         2.19412073e-01, -3.22974809e-02,  5.79142332e-01,\n",
            "        -1.55381951e-02,  2.85431355e-01,  4.88641948e-01,\n",
            "         3.49124104e-01,  1.90084070e-01, -2.36282721e-01,\n",
            "        -8.30133796e-01,  1.34123087e-01, -5.93834281e-01,\n",
            "         1.98680684e-01],\n",
            "       [-1.11360274e-01, -7.44602621e-01,  4.55822319e-01,\n",
            "         2.51620144e-01,  3.19313556e-01,  4.24932569e-01,\n",
            "         2.94771403e-01,  3.85095358e-01, -6.06057830e-02,\n",
            "         5.87938786e-01,  6.67294189e-02, -6.15046144e-01,\n",
            "        -6.98371157e-02,  4.66131479e-01,  4.25244004e-01,\n",
            "        -5.49258888e-01],\n",
            "       [ 7.97610134e-02,  9.76735801e-02,  5.46550572e-01,\n",
            "        -4.40057069e-01,  1.50681650e-02,  5.62522411e-01,\n",
            "        -2.24874139e-01,  9.24567953e-02, -1.19292691e-01,\n",
            "        -2.38007829e-01, -4.75835383e-01, -1.21944360e-01,\n",
            "        -1.77466571e-01, -2.56184101e-01,  2.13805929e-01,\n",
            "         5.45919955e-01],\n",
            "       [-1.87212795e-01,  1.19439920e-03,  1.40765712e-01,\n",
            "         2.78625280e-01,  3.57909679e-01,  2.38632128e-01,\n",
            "        -9.58977580e-01, -4.21391606e-01,  5.77610850e-01,\n",
            "        -5.13664603e-01,  1.25870124e-01, -2.99794793e-01,\n",
            "         4.61121202e-01,  5.76152980e-01,  2.36016423e-01,\n",
            "        -7.12303594e-02],\n",
            "       [ 2.98018068e-01, -3.33089620e-01,  2.41996393e-01,\n",
            "        -8.33135664e-01,  2.54506409e-01, -3.08882415e-01,\n",
            "         3.67839843e-01,  6.43501997e-01,  3.35322529e-01,\n",
            "         2.07115099e-01, -2.27969453e-01,  2.93366820e-01,\n",
            "         4.17299032e-01,  2.08147407e-01,  1.58221960e-01,\n",
            "        -3.44096065e-01],\n",
            "       [ 2.29125232e-01, -4.54297870e-01, -1.32082686e-01,\n",
            "        -2.21622214e-01,  1.33644640e-02, -8.19880128e-01,\n",
            "        -4.18117553e-01,  2.42970020e-01,  2.69273937e-01,\n",
            "         2.92504311e-01, -1.28048658e-01, -3.08447957e-01,\n",
            "         3.91657203e-01, -9.08229873e-02, -4.87295300e-01,\n",
            "         5.31447291e-01],\n",
            "       [-3.27420920e-01,  2.19389081e-01, -2.84085214e-01,\n",
            "        -4.89511907e-01,  5.20875990e-01, -9.94749069e-01,\n",
            "        -1.02390118e-01, -1.59086928e-01, -3.71851623e-02,\n",
            "         2.41165951e-01, -6.56625271e-01,  5.49478590e-01,\n",
            "        -2.68424869e-01,  5.66446424e-01,  1.67540208e-01,\n",
            "         3.92931892e-04],\n",
            "       [ 4.54155169e-02, -1.33877540e+00,  3.03261280e-01,\n",
            "        -2.04294845e-01,  6.43960357e-01,  1.47934631e-01,\n",
            "         4.75013107e-01,  2.49148428e-01, -4.09851462e-01,\n",
            "        -3.88478190e-01, -2.46440452e-02,  1.82166770e-01,\n",
            "         1.22025169e-01, -1.15831196e-01, -7.93684449e-04,\n",
            "        -1.30885211e-03],\n",
            "       [-1.99982569e-01, -2.57499397e-01, -9.13255066e-02,\n",
            "        -1.24789476e-01,  3.53271127e-01,  5.14803827e-01,\n",
            "         5.31450212e-01,  2.63059050e-01, -5.95521390e-01,\n",
            "        -1.71396449e-01, -5.51162846e-02,  8.27713236e-02,\n",
            "         5.11170998e-02,  2.63256788e-01,  4.59243506e-01,\n",
            "         1.04801975e-01],\n",
            "       [-5.40750504e-01, -1.88069627e-01, -1.62205219e-01,\n",
            "         2.27894425e-01, -2.92321235e-01, -4.82751504e-02,\n",
            "        -9.51892585e-02, -4.50517207e-01,  5.16674519e-01,\n",
            "        -2.07474545e-01,  5.44135086e-02, -9.95490476e-02,\n",
            "         2.19888642e-01, -9.19691771e-02, -3.25451195e-01,\n",
            "         4.08651471e-01],\n",
            "       [ 4.33309942e-01,  4.14335459e-01,  4.06314358e-02,\n",
            "         4.16398525e-01, -6.08875334e-01,  4.41422909e-01,\n",
            "        -1.09602153e+00, -2.60505170e-01,  4.87280518e-01,\n",
            "        -2.35395208e-01, -4.38307166e-01,  4.36523110e-01,\n",
            "        -3.12154800e-01,  2.88685471e-01,  5.10938048e-01,\n",
            "         2.99663544e-01]], dtype=float32), array([ 0.02345643,  0.27690545,  0.1330405 ,  0.21481821,  0.026307  ,\n",
            "        0.09070349, -0.08570511, -0.06103493,  0.09645463, -0.42756045,\n",
            "       -0.17406823,  0.23747216, -0.10391337, -0.04217336,  0.06131444,\n",
            "        0.20580295], dtype=float32)], [array([[-0.57357854, -0.17816159,  0.15378258, -0.28782186,  0.83922476,\n",
            "        -1.3898401 , -0.17347611, -0.29990014],\n",
            "       [ 0.83107525,  0.3480776 ,  0.16005185, -0.68829   ,  0.2989369 ,\n",
            "        -0.12358105, -1.12555   ,  0.20595632],\n",
            "       [ 0.413928  ,  0.14106578, -0.36024606,  0.55946326, -0.10864349,\n",
            "         0.32126373,  0.38955376, -0.2135944 ],\n",
            "       [ 0.1840344 ,  0.9844831 ,  0.10972476,  0.06277617,  0.21619524,\n",
            "        -0.49498162,  0.6277991 , -0.15216956],\n",
            "       [-0.0335929 , -0.91518956, -0.52856684, -0.04302125,  0.27186587,\n",
            "         0.50813586, -0.09526307,  0.338605  ],\n",
            "       [-0.16279067, -0.6155339 , -0.9241017 ,  0.8047211 ,  0.00354591,\n",
            "         0.05021275,  0.48850334,  0.28021324],\n",
            "       [ 0.53918445,  0.45828527,  0.829713  , -0.39734456, -0.84073097,\n",
            "         0.5985969 , -0.5171945 , -0.48845285],\n",
            "       [-0.68408746,  0.05445119,  0.3452918 ,  0.15570433, -0.7135976 ,\n",
            "        -0.29873735,  0.33126524,  0.41396055],\n",
            "       [ 0.45135033, -0.06245285,  0.17388515, -0.26600483, -0.66078556,\n",
            "        -0.94356996, -0.61079913,  0.10297548],\n",
            "       [ 0.04340427, -0.11605578,  0.29999837, -0.46149015, -0.4128338 ,\n",
            "         0.2711687 , -0.66315293,  0.14436658],\n",
            "       [ 0.01518322, -1.0179602 , -0.22547261,  0.27864763,  0.77383095,\n",
            "        -0.8863615 ,  0.5697478 , -1.6290877 ],\n",
            "       [ 0.16660151,  0.577805  ,  0.21494281,  0.43229133,  0.06856766,\n",
            "        -0.11398274,  0.3790134 ,  0.02107539],\n",
            "       [-1.3920687 , -0.3252374 , -0.6503325 ,  0.57415956,  0.10860094,\n",
            "        -0.04588375, -0.10818759, -1.0234782 ],\n",
            "       [ 0.4404883 ,  0.10258498, -0.37470603,  0.5110143 ,  0.1716949 ,\n",
            "         0.20197695,  0.3348931 , -0.7554079 ],\n",
            "       [ 0.23987758, -0.36200047, -0.17749909,  0.53024644,  0.53497076,\n",
            "         0.39417022,  0.31475472, -1.1108857 ],\n",
            "       [-0.6587173 ,  0.1045831 ,  0.573111  , -0.02958595,  0.37909895,\n",
            "        -1.0566678 ,  0.02886134,  0.6719224 ]], dtype=float32), array([ 0.23272665,  0.20747985,  0.26235098,  0.15472901,  0.11092371,\n",
            "       -0.00689383,  0.19630638,  0.17514668], dtype=float32)], [array([[ 0.67204297],\n",
            "       [ 0.9590573 ],\n",
            "       [ 0.49836478],\n",
            "       [-1.278454  ],\n",
            "       [-1.2134467 ],\n",
            "       [ 1.3255    ],\n",
            "       [-1.7661386 ],\n",
            "       [ 1.456993  ]], dtype=float32), array([0.08989743], dtype=float32)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcMix2u4nUXl"
      },
      "source": [
        "ann.save_weights(\"/content/drive/MyDrive/weights2.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPws2teIosVL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}